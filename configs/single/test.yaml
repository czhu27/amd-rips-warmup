batch_size: 4096
# batch_size: 16384
# layers: [3,20, 20, 20, 1]
layers: [3, 100, 100, 100, 100, 100, 1]
lr: 1.0e-4
grad_reg_const: 1
gradient_loss: second_explicit
epochs: 10000