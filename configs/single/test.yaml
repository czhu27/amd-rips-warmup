batch_size: 512
# batch_size: 16384
# layers: [3,20, 20, 20, 1]
layers: [3, 100, 100, 100, 100, 100, 1]
# lr: 1.e-5
grad_reg_const: 1
# activation: swish
# gradient_loss: second_explicit
epochs: 5000

from_tensor_slices: true