batch_size: 512
layers: [3, 100, 100, 100, 100, 100, 1]
lr: 1.0e-3
grad_reg_const: 0.1     # !!!
activation: tanh
model_outputs: pressure
gradient_loss: second_explicit
epochs: 5000
lr_scheduler: false
lr_scheduler_params: [1.0e-3, 1.0e-5, 50000, 1.0] #[initial, final, decay_steps, power]


from_tensor_slices: false