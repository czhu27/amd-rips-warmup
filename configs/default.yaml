###########
#  Model  #
###########
activation: elu
layers: [2, 20, 20, 20, 1]

##############
#  Training  #
##############
epochs: 1000
batch_size: 256
lr: 1.0e-4
lr_scheduler: false
lr_scheduler_params: [1.0e-3, 1.0e-6, 2500, 1.0] #[initial, final, decay_steps, power]

#############
#  Dataset  #
#############
output_dir: null   # overridden in main.py
f_a: 1.0
f_b: 1.0
corners: false
dataset: [10000, 0, 500, 1.0, 1.0] #[interior, exterior, border, labeled_int%, labeled_ext%]
noise: 0.01

##################
#  Regularizers  #
##################
regularizer: none
reg_const: 0.1
gradient_loss: false  # l1 (l2?)
grad_reg_const: 1

#############
#  Logging  #
#############
debug: false
plots: true
detailed_save: true