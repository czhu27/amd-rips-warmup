###########
#  Model  #
###########
activation: tanh
dropout_rates: 0.0
layers: [3, 20, 20, 20, 1]

##############
#  Training  #
##############
device: gpu
trials: 1
seed: 0
epochs: 12000
batch_size: 256
lr: 1.0e-4
lr_scheduler: false
lr_scheduler_type: piecewise_linear
lr_scheduler_params: [1.0e-3, 1.0e-6, 2500, 1.0] #[initial, final, decay_steps, power]
gd_noise: 0.0

#############
#  Dataset  #
#############
#source: wave_with_source
source: wave
data_dir: data/wave
data_run: [fine_mesh_gauss_few] 

corners: false
dataset: [2500, 7500, 0, 1.0, 0.0] #[interior, exterior, border, labeled_int%, labeled_ext%]
noise: 0.0

from_tensor_slices: true

# make sure data_sources correspond with files in data_run
# also make sure data_sources is list of points
#data_sources: [[0.5, 0.5], [0.9, 0.1], [0.25, 0.75]]
#data_run: [05-05, 09-01, 025-075]

# test_source and test_data_dir only matter for error calculation and prediction plots
# test_source: [0.6, 0.6]
# test_data_dir: data/wave/06-06/
shuffle: true

##################
#  Regularizers  #
##################
regularizer: none
reg_const: 0.1
# none, const, zero, first
model_outputs: pressure
gradient_loss: none
loss_schedulerizer: true
loss_schedulerizer_params: [500,2000] #[Begin adding grad, fully added]
#grad_reg_norm: l1 l2
grad_reg_const: 1
# grad_reg_scheduler: late_start
# grad_reg_start: 

#############
#  Logging  #
#############
debug: false
output_dir: null   # overridden in main.py
output_root: output/wave
plots: [extrapolation, data-distribution, tensorboard, extrapolation_wave, heatmap]
saves: [model]
tb_error_timestep: 100
